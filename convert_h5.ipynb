{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_bucket(bucket):\n",
    "    client = boto3.client('s3')\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "    page_iterator = paginator.paginate(Bucket=bucket)\n",
    "    \n",
    "    for page in page_iterator:\n",
    "        if page['KeyCount'] > 0:\n",
    "            for item in page['Contents']:\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time passed =  194.2010359764099\n"
     ]
    }
   ],
   "source": [
    "pathlist=[]\n",
    "start = time.time()\n",
    "#for i in iterate_bucket(bucket='millionsongproject'):\n",
    "for i in iterate_bucket(bucket='millionsongproject'):\n",
    "    if i['Key'].endswith('.h5') and not i['Key']=='millionsongsubset/MillionSongSubset/AdditionalFiles/subset_msd_summary_file.h5':\n",
    "        pathlist.append(i['Key'])\n",
    "print(\"time passed = \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time passed =  0.7620112895965576\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "start = time.time()\n",
    "random.shuffle(pathlist)\n",
    "print(\"time passed = \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext()\n",
    "ss=SparkSession \\\n",
    ".builder \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rdd=sc.parallelize(pathlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "time passed =  0.3231816291809082\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(path_rdd.count())\n",
    "print(\"time passed = \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_iter=path_rdd.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L/M/I/TRLMICH128F9324111.h5'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(path_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_sample_rate=[]\n",
    "artist_7digitalid=[]\n",
    "artist_familiarity=[]\n",
    "artist_hotttnesss=[]\n",
    "artist_id=[]\n",
    "artist_latitude=[]\n",
    "artist_location=[]\n",
    "artist_longitude=[]\n",
    "artist_mbid=[]\n",
    "artist_mbtags=[]\n",
    "artist_mbtags_count=[]\n",
    "artist_name=[]\n",
    "artist_playmeid=[]\n",
    "artist_terms=[]\n",
    "artist_terms_freq=[]\n",
    "artist_terms_weight=[]\n",
    "audio_md5=[]\n",
    "bars_confidence=[]\n",
    "bars_start=[]\n",
    "beats_confidence=[]\n",
    "beats_start=[]\n",
    "danceability=[]\n",
    "duration=[]\n",
    "end_of_fade_in=[]\n",
    "energy=[]\n",
    "key=[]\n",
    "key_confidence=[]\n",
    "loudness=[]\n",
    "mode=[]\n",
    "mode_confidence=[]\n",
    "release=[]\n",
    "release_7digitalid=[]\n",
    "sections_confidence=[]\n",
    "sections_start=[]\n",
    "segments_confidence=[]\n",
    "segments_loudness_max=[]\n",
    "segments_loudness_max_time=[]\n",
    "segments_loudness_start=[]\n",
    "segments_pitches=[]\n",
    "segments_start=[]\n",
    "segments_timbre=[]\n",
    "similar_artists=[]\n",
    "song_hotttnesss=[]\n",
    "song_id=[]\n",
    "start_of_fade_out=[]\n",
    "tatums_confidence=[]\n",
    "tatums_start=[]\n",
    "tempo=[]\n",
    "time_signature=[]\n",
    "time_signature_confidence=[]\n",
    "title=[]\n",
    "track_7digitalid=[]\n",
    "track_id=[]\n",
    "year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files done =  81 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/miniconda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/hadoop/miniconda/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files done =  25948 6  5331 10717 15067 "
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "import h5py_getter\n",
    "s3 = s3fs.S3FileSystem()\n",
    "BUCKET='s3://millionsongproject/'\n",
    "counter=0\n",
    "start = time.time()\n",
    "for a in path_iter:\n",
    "    if counter < 200000:\n",
    "        address=BUCKET+a\n",
    "        with h5py.File(s3.open(address, 'rb'), 'r', lib_version='latest') as f:\n",
    "            analysis_sample_rate.append(h5py_getter.get_analysis_sample_rate(f))\n",
    "            #artist_7digitalid.append(h5py_getter.get_artist_7digitalid(f))\n",
    "            artist_familiarity.append(h5py_getter.get_artist_familiarity(f))\n",
    "            artist_hotttnesss.append(h5py_getter.get_artist_hotttnesss(f))\n",
    "            artist_id.append(h5py_getter.get_artist_id(f))\n",
    "            artist_latitude.append(h5py_getter.get_artist_latitude(f))\n",
    "            artist_location.append(h5py_getter.get_artist_location(f))\n",
    "            artist_longitude.append(h5py_getter.get_artist_longitude(f))\n",
    "            #artist_mbid.append(h5py_getter.get_artist_mbid(f))\n",
    "            #artist_mbtags.append(h5py_getter.get_artist_mbtags(f))\n",
    "            #artist_mbtags_count.append(h5py_getter.get_artist_mbtags_count(f))\n",
    "            artist_name.append(h5py_getter.get_artist_name(f))\n",
    "            #artist_playmeid.append(h5py_getter.get_artist_playmeid(f))\n",
    "            artist_terms.append(h5py_getter.get_artist_terms(f))\n",
    "            artist_terms_freq.append(h5py_getter.get_artist_terms_freq(f))\n",
    "            #artist_terms_weight.append(h5py_getter.get_artist_terms_weight(f))\n",
    "            #audio_md5.append(h5py_getter.get_audio_md5(f))\n",
    "            bars_confidence.append(h5py_getter.get_bars_confidence(f))\n",
    "            bars_start.append(h5py_getter.get_bars_start(f))\n",
    "            beats_confidence.append(h5py_getter.get_beats_confidence(f))\n",
    "            beats_start.append(h5py_getter.get_beats_start(f))\n",
    "            danceability.append(h5py_getter.get_danceability(f))\n",
    "            duration.append(h5py_getter.get_duration(f))\n",
    "            end_of_fade_in.append(h5py_getter.get_end_of_fade_in(f))\n",
    "            energy.append(h5py_getter.get_energy(f))\n",
    "            key.append(h5py_getter.get_key(f))\n",
    "            key_confidence.append(h5py_getter.get_key_confidence(f))\n",
    "            loudness.append(h5py_getter.get_loudness(f))\n",
    "            mode.append(h5py_getter.get_mode(f))\n",
    "            mode_confidence.append(h5py_getter.get_mode_confidence(f))\n",
    "            release.append(h5py_getter.get_release(f))\n",
    "            #release_7digitalid.append(h5py_getter.get_release_7digitalid(f))\n",
    "            sections_confidence.append(h5py_getter.get_sections_confidence(f))\n",
    "            sections_start.append(h5py_getter.get_sections_start(f))\n",
    "            segments_confidence.append(h5py_getter.get_segments_confidence(f))\n",
    "            segments_loudness_max.append(h5py_getter.get_segments_loudness_max(f))\n",
    "            segments_loudness_max_time.append(h5py_getter.get_segments_loudness_max_time(f))\n",
    "            segments_loudness_start.append(h5py_getter.get_segments_loudness_start(f))\n",
    "            segments_pitches.append(h5py_getter.get_segments_pitches(f))\n",
    "            segments_start.append(h5py_getter.get_segments_start(f))\n",
    "            segments_timbre.append(h5py_getter.get_segments_timbre(f))\n",
    "            similar_artists.append(h5py_getter.get_similar_artists(f))\n",
    "            song_hotttnesss.append(h5py_getter.get_song_hotttnesss(f))\n",
    "            song_id.append(h5py_getter.get_song_id(f))\n",
    "            start_of_fade_out.append(h5py_getter.get_start_of_fade_out(f))\n",
    "            tatums_confidence.append(h5py_getter.get_tatums_confidence(f))\n",
    "            tatums_start.append(h5py_getter.get_tatums_start(f))\n",
    "            tempo.append(h5py_getter.get_tempo(f))\n",
    "            time_signature.append(h5py_getter.get_time_signature(f))\n",
    "            time_signature_confidence.append(h5py_getter.get_time_signature_confidence(f))\n",
    "            title.append(h5py_getter.get_title(f))\n",
    "            #track_7digitalid.append(h5py_getter.get_track_7digitalid(f))\n",
    "            #track_id.append(h5py_getter.get_track_id(f))\n",
    "            year.append(h5py_getter.get_year(f))\n",
    "            counter +=1\n",
    "            print(\"\\rNumber of files done = \", counter, end=' ')\n",
    "    else:\n",
    "        break\n",
    "print(\"time passed = \", time.time()-start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df = pd.DataFrame()\n",
    "df['analysis_sample_rate']=pd.Series(analysis_sample_rate)\n",
    "#df['artist_7digitalid']=pd.Series(artist_7digitalid)\n",
    "df['artist_familiarity']=pd.Series(artist_familiarity)\n",
    "df['artist_hotttnesss']=pd.Series(artist_hotttnesss)\n",
    "df['artist_id']=pd.Series([s.decode('utf-8') for s in artist_id])\n",
    "df['artist_latitude']=pd.Series(artist_latitude)\n",
    "df['artist_location']=pd.Series([s.decode('utf-8') for s in artist_location])\n",
    "df['artist_longitude']=pd.Series(artist_longitude)\n",
    "#df['artist_mbid']=pd.Series(artist_mbid)\n",
    "#df['artist_mbtags']=pd.Series(artist_mbtags)\n",
    "#df['artist_mbtags_count']=pd.Series(artist_mbtags_count)\n",
    "df['artist_name']=pd.Series([s.decode('utf-8') for s in artist_name])\n",
    "#df['artist_playmeid']=pd.Series(artist_playmeid)\n",
    "df['artist_terms']=pd.Series(s.astype('U') for s in artist_terms)\n",
    "df['artist_terms_freq']=pd.Series(artist_terms_freq)\n",
    "#df['artist_terms_weight']=pd.Series(artist_terms_weight)\n",
    "#df['audio_md5']=pd.Series(audio_md5)\n",
    "df['bars_confidence']=pd.Series(bars_confidence)\n",
    "df['bars_start']=pd.Series(bars_start)\n",
    "df['beats_confidence']=pd.Series(beats_confidence)\n",
    "df['beats_start']=pd.Series(beats_start)\n",
    "df['danceability']=pd.Series(danceability)\n",
    "df['duration']=pd.Series(duration)\n",
    "df['end_of_fade_in']=pd.Series(end_of_fade_in)\n",
    "df['energy']=pd.Series(energy)\n",
    "df['key']=pd.Series(key)\n",
    "df['key_confidence']=pd.Series(key_confidence)\n",
    "df['loudness']=pd.Series(loudness)\n",
    "df['mode']=pd.Series(mode)\n",
    "df['mode_confidence']=pd.Series(mode_confidence)\n",
    "df['release']=pd.Series([s.decode('utf-8') for s in release])\n",
    "#df['release_7digitalid']=pd.Series(release_7digitalid)\n",
    "df['sections_confidence']=pd.Series(sections_confidence)\n",
    "df['sections_start']=pd.Series(sections_start)\n",
    "df['segments_confidence']=pd.Series(segments_confidence)\n",
    "df['segments_loudness_max']=pd.Series(segments_loudness_max)\n",
    "df['segments_loudness_max_time']=pd.Series(segments_loudness_max_time)\n",
    "df['segments_loudness_start']=pd.Series(segments_loudness_start)\n",
    "df['segments_pitches']=pd.Series(segments_pitches)\n",
    "df['segments_start']=pd.Series(segments_start)\n",
    "df['segments_timbre']=pd.Series(segments_timbre)\n",
    "df['similar_artists']=pd.Series(similar_artists)\n",
    "df['song_hotttnesss']=pd.Series(song_hotttnesss)\n",
    "df['song_id']=pd.Series([s.decode('utf-8') for s in song_id])\n",
    "df['start_of_fade_out']=pd.Series(start_of_fade_out)\n",
    "df['tatums_confidence']=pd.Series(tatums_confidence)\n",
    "df['tatums_start']=pd.Series(tatums_start)\n",
    "df['tempo']=pd.Series(tempo)\n",
    "df['time_signature']=pd.Series(time_signature)\n",
    "df['time_signature_confidence']=pd.Series(time_signature_confidence)\n",
    "df['title']=pd.Series([s.decode('utf-8') for s in title])\n",
    "#df['track_7digitalid']=pd.Series(track_7digitalid)\n",
    "#df['track_id']=pd.Series(track_id)\n",
    "df['year']=pd.Series(year)\n",
    "print(\"time passed = \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('big_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = ss.read.csv('big_subset.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=test_file.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rdd(feature_rdd, data):\n",
    "    data=data.tolist()\n",
    "    data=[data]\n",
    "    temp_rdd=sc.parallelize(data)\n",
    "    return feature_rdd.union(temp_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import s3fs\n",
    "import h5py_getter\n",
    "from pyspark.sql import Row\n",
    "s3 = s3fs.S3FileSystem()\n",
    "address='s3://cosc502millionsong/millionsongsubset/MillionSongSubset/data/A/A/A/TRAAAAW128F429D538.h5'\n",
    "attributes = ['artist_7digitalid','artist_familiarity','artist_hotttnesss','artist_id',\n",
    "     'artist_latitude','artist_location','artist_longitude','artist_mbidartist_mbtags',\n",
    "     'artist_mbtags_count','artist_name','artist_playmeid','artist_terms',\n",
    "     'artist_terms_freq','artist_terms_weight','audio_md5', 'bars_confidence','bars_start',\n",
    "     'beats_confidence','beats_start','danceability','duration','end_of_fade_in',\n",
    "     'energy','key','key_confidence','loudness','mode','mode_confidence',\n",
    "     'release','release_7digitalid','sections_confidence','sections_start',\n",
    "     'segments_confidence','segments_loudness_max','segments_loudness_max_time',\n",
    "     'segments_loudness_start','segments_pitches','segments_start','segments_timbre',\n",
    "     'similar_artists','song_hotttnesss','song_id','start_of_fade_out','tatums_confidence',\n",
    "     'tatums_start','tempo','time_signature','time_signature_confidence','title','track_7digitalid',\n",
    "     'track_id','year']\n",
    "with h5py.File(s3.open(address, 'rb'), 'r', lib_version='latest') as f:\n",
    "    analysis_sample_rate=append_rdd(analysis_sample_rate, h5py_getter.get_analysis_sample_rate(f))\n",
    "    artist_7digitalid=append_rdd(artist_7digitalid, h5py_getter.get_artist_7digitalid(f))\n",
    "    artist_familiarity=append_rdd(artist_familiarity, h5py_getter.get_artist_familiarity(f))\n",
    "    artist_hotttnesss=append_rdd(artist_hotttnesss, h5py_getter.get_artist_hotttnesss(f))\n",
    "    artist_id=append_rdd(artist_id, h5py_getter.get_artist_id(f))\n",
    "    artist_latitude=append_rdd(artist_latitude, h5py_getter.get_artist_latitude(f))\n",
    "    artist_location=append_rdd(artist_location, h5py_getter.get_artist_location(f))\n",
    "    artist_longitude=append_rdd(artist_longitude, h5py_getter.get_artist_longitude(f))\n",
    "    artist_mbid=append_rdd(artist_mbid, h5py_getter.get_artist_mbid(f))\n",
    "    artist_mbtags=append_rdd(artist_mbtags, h5py_getter.get_artist_mbtags(f))\n",
    "    artist_mbtags_count=append_rdd(artist_mbtags_count, h5py_getter.get_artist_mbtags_count(f))\n",
    "    artist_name=append_rdd(artist_name, h5py_getter.get_artist_name(f))\n",
    "    artist_playmeid=append_rdd(artist_playmeid, h5py_getter.get_artist_playmeid(f))\n",
    "    artist_terms=append_rdd(artist_terms, h5py_getter.get_artist_terms(f))\n",
    "    artist_terms_freq=append_rdd(artist_terms_freq, h5py_getter.get_artist_terms_freq(f))\n",
    "    artist_terms_weight=append_rdd(artist_terms_weight, h5py_getter.get_artist_terms_weight(f))\n",
    "    audio_md5=append_rdd(audio_md5, h5py_getter.get_audio_md5(f))\n",
    "    bars_confidence=append_rdd(bars_confidence, h5py_getter.get_bars_confidence(f))\n",
    "    bars_start=append_rdd(bars_start, h5py_getter.get_bars_start(f))\n",
    "    beats_confidence=append_rdd(beats_confidence, h5py_getter.get_beats_confidence(f))\n",
    "    beats_start=append_rdd(beats_start, h5py_getter.get_beats_start(f))\n",
    "    danceability=append_rdd(danceability, h5py_getter.get_danceability(f))\n",
    "    duration=append_rdd(duration, h5py_getter.get_duration(f))\n",
    "    end_of_fade_in=append_rdd(end_of_fade_in, h5py_getter.get_end_of_fade_in(f))\n",
    "    energy=append_rdd(energy, h5py_getter.get_energy(f))\n",
    "    key=append_rdd(key, h5py_getter.get_key(f))\n",
    "    key_confidence=append_rdd(key_confidence, h5py_getter.get_key_confidence(f))\n",
    "    loudness=append_rdd(loudness, h5py_getter.get_loudness(f))\n",
    "    mode=append_rdd(mode, h5py_getter.get_mode(f))\n",
    "    mode_confidence=append_rdd(mode_confidence, h5py_getter.get_mode_confidence(f))\n",
    "    release=append_rdd(release, h5py_getter.get_release(f))\n",
    "    release_7digitalid=append_rdd(release_7digitalid, h5py_getter.get_release_7digitalid(f))\n",
    "    sections_confidence=append_rdd(sections_confidence, h5py_getter.get_sections_confidence(f))\n",
    "    sections_start=append_rdd(sections_start, h5py_getter.get_sections_start(f))\n",
    "    segments_confidence=append_rdd(segments_confidence, h5py_getter.get_segments_confidence(f))\n",
    "    segments_loudness_max=append_rdd(segments_loudness_max, h5py_getter.get_segments_loudness_max(f))\n",
    "    segments_loudness_max_time=append_rdd(segments_loudness_max_time, h5py_getter.get_segments_loudness_max_time(f))\n",
    "    segments_loudness_start=append_rdd(segments_loudness_start, h5py_getter.get_segments_loudness_start(f))\n",
    "    segments_pitches=append_rdd(segments_pitches, h5py_getter.get_segments_pitches(f))\n",
    "    segments_start=append_rdd(segments_start, h5py_getter.get_segments_start(f))\n",
    "    segments_timbre=append_rdd(segments_timbre, h5py_getter.get_segments_timbre(f))\n",
    "    similar_artists=append_rdd(similar_artists, h5py_getter.get_similar_artists(f))\n",
    "    song_hotttnesss=append_rdd(song_hotttnesss, h5py_getter.get_song_hotttnesss(f))\n",
    "    song_id=append_rdd(song_id, h5py_getter.get_song_id(f))\n",
    "    start_of_fade_out=append_rdd(start_of_fade_out, h5py_getter.get_start_of_fade_out(f))\n",
    "    tatums_confidence=append_rdd(tatums_confidence, h5py_getter.get_tatums_confidence(f))\n",
    "    tatums_start=append_rdd(tatums_start, h5py_getter.get_tatums_start(f))\n",
    "    tempo=append_rdd(tempo, h5py_getter.get_tempo(f))\n",
    "    time_signature=append_rdd(time_signature, h5py_getter.get_time_signature(f))\n",
    "    time_signature_confidence=append_rdd(time_signature_confidence, h5py_getter.get_time_signature_confidence(f))\n",
    "    title=append_rdd(title, h5py_getter.get_title(f))\n",
    "    track_7digitalid=append_rdd(track_7digitalid, h5py_getter.get_track_7digitalid(f))\n",
    "    track_id=append_rdd(track_id, h5py_getter.get_track_id(f))\n",
    "    year=append_rdd(year, h5py_getter.get_year(f))\n",
    "errors=0\n",
    "\n",
    "row=Row('analysis_sample_rate')\n",
    "df = analysis_sample_rate.map(row).toDF()\n",
    "for attribute in attributes:\n",
    "    row=Row(attribute)\n",
    "    tempdf = globals()[attribute].map(row).toDF()\n",
    "    #df=df.withColumn(attribute, lit(None)).select(df.columns)\n",
    "    #for c in df.columns:\n",
    "        #tempdf=tempdf.withColumn(c, lit(None)).select(tempdf.columns)\n",
    "    df=df.union(tempdf)\n",
    "\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
