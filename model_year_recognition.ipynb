{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "     .appName(\"Test SparkSession\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in=spark.read.load(\"s3://lusun-bucket1/clean_big_subset.csv\",format=\"csv\",header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', analysis_sample_rate='22050', artist_familiarity='0.6479336219623286', artist_hotttnesss='0.4820228266956789', artist_id='AR4PQ891187FB5CA9F', artist_latitude='40.76099', artist_location='East Orange, NJ', artist_longitude='-74.20991', artist_name='Dionne Warwick', artist_terms=\"['brill building pop', 'quiet storm', 'ballad', 'easy listening', 'motown', 'disco', 'soul jazz', 'smooth jazz', 'soul', 'jazz', 'soft rock', 'uk garage', 'chill-out', 'german pop', 'salsa', 'r&b', 'chanson', 'rock', 'pop', 'blues-rock', 'vocal jazz', 'funk', 'oldies', 'pop rock', 'downtempo', 'hip hop', 'classic rock', 'united states', 'germany', 'adult contemporary', 'folk rock', 'vocal', 'soundtrack', 'blues', 'female vocalist', 'electronic', 'new wave', 'urban', 'reggae', 'singer-songwriter', 'swing', '60s', 'female', 'american', '80s', '90s', 'ambient']\", artist_terms_freq='0.7901756112133602', bars_confidence='0.09891509433962263', bars_start='109.345429245283', beats_confidence='0.555841121495327', beats_start='110.11071338785048', danceability=0.0, duration=222.90240478515625, end_of_fade_in='0.299', energy=0.0, key='5', key_confidence='0.762', loudness=-15.279999732971191, mode='1', mode_confidence='0.613', release='Friends', sections_confidence='0.5946', sections_start='96.034035', segments_confidence='0.6345415430267063', segments_loudness_max='-18.31317210682493', segments_loudness_max_time='(674,)', segments_loudness_start='-27.020842729970326', segments_pitches='(674, 12)', segments_start='111.5988821364985', segments_timbre='(674, 12)', similar_artists='(100,)', song_hotttnesss='0.24906579485370345', song_id='SOWTLUT12A8C13BE83', start_of_fade_out='210.396', tatums_confidence='0.5210292056074767', tatums_start='110.2390154088785', tempo=116.86599731445312, time_signature='4', time_signature_confidence='0.981', title='Remember Your Heart', year=1985, period=4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_in.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType,IntegerType\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "#convert field type\n",
    "float_list=['duration','tempo','loudness','energy','danceability','song_hotttnesss','artist_hotttnesss']\n",
    "\n",
    "for item in float_list:\n",
    "    df_in = df_in.withColumn(item, df_in[item].cast(FloatType()))\n",
    "    \n",
    "df_in = df_in.withColumn(\"year\", df_in[\"year\"].cast(IntegerType()))\n",
    "\n",
    "df_in = df_in.withColumn(\"period\", \\\n",
    "              when(df_in[\"year\"] <1950, 0).when(df_in[\"year\"] <1960, 1).when(df_in[\"year\"] <1970, 2).when(df_in[\"year\"] <1980, 3)\\\n",
    "                         .when(df_in[\"year\"] <1990, 4).when(df_in[\"year\"] <2000, 5).when(df_in[\"year\"] <2010, 6).when(df_in[\"year\"] <2020, 7).otherwise(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|period|\n",
      "+------+\n",
      "|     4|\n",
      "|     6|\n",
      "|     5|\n",
      "|     5|\n",
      "|     0|\n",
      "|     6|\n",
      "|     0|\n",
      "|     0|\n",
      "|     5|\n",
      "|     2|\n",
      "|     0|\n",
      "|     6|\n",
      "|     5|\n",
      "|     6|\n",
      "|     5|\n",
      "|     6|\n",
      "|     0|\n",
      "|     5|\n",
      "|     8|\n",
      "|     5|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler,StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "df_in.select('period').show()\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=float_list,\n",
    "    outputCol=\"features\",handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_in.randomSplit([0.95, 0.05], seed=10)\n",
    "p1=Pipeline(stages=[assembler])\n",
    "training_data=p1.fit(train).transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier,GBTClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"period\", featuresCol=\"features\", numTrees=20)\n",
    "pipeline=Pipeline(stages=[rf])\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=p1.fit(test).transform(test)\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5461830451286377\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"period\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
